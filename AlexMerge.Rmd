---
title: "AlexMerge"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(foreign)
library(tidyverse)
library(DMwR2)
library(e1071)
library(glmnet)



data_merge1<-read.spss("data/W1 Merged Data/Wave.1_Data/Merge/Wave1_20170906.sav", 
                  to.data.frame=TRUE)

# data_merge1 <- data_merge1%>%
#   select(se002, se005, se009, country, q007, q008, q009, q010, q006, q098, q128, q005, q027, q105, q106, q123, q127)
data_merge1 <- data_merge1%>%
   select(se002, se005, se009, country, q027, q105, q106)



#data_merge1<- knnImputation(data_merge1, k = 10)



#data_merge2<-read.spss("data/W2 Merged Data/2w-3rd_release_all/merge/Wave2_20170724.sav", 
                  #to.data.frame=TRUE)
#data_merge2

#tune.out <- tune(svm, q106 ~ ., data = data_merge1, kernel = "linear",
                 #ranges = list(cost = c(0.001, 0.01, 0.1,
                  #                      1, 5, 10, 100)))
#summary(tune.out)


```

```{r}
# data_merge1 <- na.omit(data_merge1)
# data_merge1
# # data_merge1 <- data_merge1%>% 
# #   mutate(q106 = case_when(q106=="Much worse" ~ 0,
# #                           q106=="Somewhat worse" ~ 1,
# #                           q106=="Much the same" ~ 2,
# #                           q106=="Somewhat better" ~ 3,
# #                           q106=="Much better that before" ~ 4,))
# x <- model.matrix(q106~.,data_merge1)
# x
# y <- data_merge1$q106
# #Finding optimal lambda shrinkage value to reduce error through cross validation
# set.seed(123)
# cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "multinomial")
# #Creation of lasso model and outputting regression coefficients
# lasso_model <- glmnet(x, y, alpha = 1, family = "multinomial",
# lambda = cv.lasso$lambda.min)
# coef(lasso_model)

```
```{r}
tune.out1 <- tune(svm, q106 ~ ., data = data_merge1, kernel = "linear",
                 ranges = list(cost = c(0.001, 0.01, 0.1,
                                        1, 5, 10, 100)))
summary(tune.out1)

```

```{r}

data_merge1 <- data_merge1%>% 
  drop_na() 
data_merge1 %>%
  count(country)

data_merge1 <- data_merge1%>% 
   mutate(q106 = case_when(q106=="Much worse" ~ 0,
                           q106=="Somewhat worse" ~ 0,
                           q106=="Much the same" ~ 0,
                           q106=="Somewhat better" ~ 1,
                           q106=="Much better than before" ~ 1,))
x <- model.matrix(q106~.,data_merge1)[,-1]
x
y <- data_merge1$q106
#Finding optimal lambda shrinkage value to reduce error through cross validation
set.seed(123)
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
#Creation of lasso model and outputting regression coefficients
lasso_model <- glmnet(x, y, alpha = 1, family = "binomial",
lambda = cv.lasso$lambda.min)
coef(lasso_model)
cv.lasso$lambda.min
```
We decided to transform our response variable q106 into two different categories. "Much worse," "Somewhat worse," "Much the same," were encoded as 0, and "Somewhat better, "Much better than before" were encoded as 1. As a result, our goal is to predict if trends in the equal treatment of citizens has gotten worse/stayed the same, or gotten better. We decided to drop all NA's from the dataframe. We considered using KNN to impute missing values, but we thought the missing data may have a systematic pattern, as seen in the GRAPHHHHH, and the large amount of missing values were computationally expensive to fit given the number of dimensions. 

We then decided to fit a logistic lasso regression in order to decrease the variance of our model and also perform variable selection. Shrinkage of the coefficients also may help with multicollinearity in the model. We used cross validation to find the optimal lambda shrinkage parameter, and used that as the lambda parameter in our final model. 



Given more time, we would like to explore more interaction effects. In addition, we would also include Wave2 as a predictor variable and merge in the Wave2 data. Also, another thing we want to consider is the handling of missing data. Part of the reason we didn't use certain predictors, for example age, is because certain countries did not report them at all. We were wondering if there was a better way to fix this problem. Plenty of other observations had missing values as well, so we wanted to find a statistically sound way to impute them. Finally, we wanted to find other models that might fit well. For example, we fit a SVM but scrapped it because we were not sure about performing proper variable selection with SVM's. In addition, decision trees seem like possible idea, as they handle categorical predictors and responses well. 